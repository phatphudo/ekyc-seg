{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_cv_img(img):\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_corners(img, corners):\n",
    "    for corner in corners:\n",
    "        cv2.circle(img, tuple(map(int, corner)), radius=10, color=(255, 0, 0), thickness=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/'\n",
    "DIR_SRC = DATA_DIR + 'background/'\n",
    "DIR_DST = DATA_DIR + 'synthetic/resized_bg/'\n",
    "if not os.path.exists(DIR_DST):\n",
    "    os.mkdir(DIR_DST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000_F_298240692_uohz4LEqlbe0lMlRhPOBzXcNVFyl8Wws.jpg : (667, 1000, 3)\n",
      "1557845371_sangach_(8).jpg : (768, 1024, 3)\n",
      "2-56a2fc1b5f9b58b7d0cffb23.jpg : (600, 900, 3)\n",
      "3703784863_1bfb1c0197.jpg : (375, 500, 3)\n",
      "41532873-pink-fabric-texture-textile-background-woolen-texture-background-knitted-wool-fabric-pink-hairy-fluf.webp : (866, 1300, 3)\n",
      "6916821778_86b64ecc04_b.jpg : (576, 1024, 3)\n",
      "88f834fd8f6641bf4056a128f654fc75.jpg : (934, 1400, 3)\n",
      "background-1838494__480.jpg : (480, 719, 3)\n",
      "bg_0.jpeg : (1024, 1365, 3)\n",
      "bg_1.png : (1024, 1365, 3)\n",
      "bg_2.jpg : (1024, 1024, 3)\n",
      "bg_3.jpg : (523, 640, 3)\n",
      "bg_4.jpg : (631, 950, 3)\n",
      "bg_5.png : (376, 550, 3)\n",
      "bg_6.jpg : (1280, 1440, 3)\n",
      "bg_7.png : (866, 1300, 3)\n",
      "bg_8.png : (866, 1300, 3)\n",
      "bg_9.jpg : (1280, 1280, 3)\n",
      "brown-fabric-wallpaper-texture-background-vintage-73335917.jpg : (533, 800, 3)\n",
      "carpet-surface-closeup-as-background-36601006.jpg : (533, 800, 3)\n",
      "depositphotos_128693244-stock-photo-closeup-surface-abstract-fabric-pattern.jpg : (768, 1024, 3)\n",
      "depositphotos_347953152-stock-photo-green-cloth-background-rough-cotton.webp : (450, 600, 3)\n",
      "Floor-Surfaces.jpg : (652, 830, 3)\n",
      "gach-do-lat-san-loai-re-1200x675.jpg : (675, 1200, 3)\n",
      "gach-lat-san-vuon-taicera-G63128.jpg : (397, 500, 3)\n",
      "google_0007.jpg : (768, 1024, 3)\n",
      "google_0016.jpg : (1093, 1500, 3)\n",
      "google_0045.jpg : (444, 710, 3)\n",
      "google_0047.jpg : (2333, 3500, 3)\n",
      "google_0050.jpg : (586, 880, 3)\n",
      "google_0059.jpg : (400, 750, 3)\n",
      "Grasshopper-Green-Sashiko-Fabric.jpg : (1280, 1280, 3)\n",
      "HD-wallpaper-brown-leather-texture-fabric-texture-brown-leather-background-leather-texture.jpg : (500, 800, 3)\n",
      "image5s.jpeg : (225, 225, 3)\n",
      "images.jpeg : (183, 275, 3)\n",
      "index.jpeg : (168, 299, 3)\n",
      "istockphoto-1058849314-1024x1024.jpg : (682, 1024, 3)\n",
      "istockphoto-1166749957-612x612.jpg : (459, 612, 3)\n",
      "istockphoto-1203918823-170667a.jpg : (339, 509, 3)\n",
      "istockphoto-482784981-612x612.jpg : (408, 612, 3)\n",
      "istockphoto-901437292-170667a.jpg : (339, 509, 3)\n",
      "light-brown-soft-wood-floor-surface-texture-as-background-wooden-parquet-old-grunge-washed-oak-laminate-pattern-top-view-113469026.jpg : (420, 800, 3)\n",
      "mat-ban-mfc-mau-vang.jpeg : (1024, 1365, 3)\n",
      "nassver_0018.jpg : (340, 340, 3)\n",
      "naversss_0005.jpg : (228, 340, 3)\n",
      "naversss_0021.jpg : (261, 340, 3)\n",
      "naverss_0024.jpg : (453, 340, 3)\n",
      "navers_0042.jpg : (340, 340, 3)\n",
      "naver_0001.jpg : (340, 340, 3)\n",
      "naver_0002.jpg : (293, 340, 3)\n",
      "naver_0003.jpg : (240, 340, 3)\n",
      "naver_0004.jpg : (237, 340, 3)\n",
      "naver_0005.jpg : (453, 340, 3)\n",
      "naver_0006.jpg : (445, 340, 3)\n",
      "naver_0007.jpg : (512, 340, 3)\n",
      "naver_0008.jpg : (340, 340, 3)\n",
      "naver_0009.jpg : (340, 340, 3)\n",
      "naver_0010.jpg : (453, 340, 3)\n",
      "naver_0011.jpg : (214, 340, 3)\n",
      "naver_0012.jpg : (512, 512, 3)\n",
      "naver_0013.jpg : (340, 340, 3)\n",
      "naver_0014.jpg : (340, 340, 3)\n",
      "naver_0015.jpg : (340, 340, 3)\n",
      "naver_0016.jpg : (340, 340, 3)\n",
      "naver_0017.jpg : (378, 340, 3)\n",
      "naver_0017.png : (600, 340, 3)\n",
      "naver_0018.jpg : (207, 340, 3)\n",
      "naver_0018dd.jpg : (453, 340, 3)\n",
      "naver_0019.jpg : (510, 340, 3)\n",
      "naver_0020.jpg : (227, 340, 3)\n",
      "naver_0021.jpg : (413, 340, 3)\n",
      "naver_0022.jpg : (340, 340, 3)\n",
      "naver_0023.jpg : (255, 340, 3)\n",
      "naver_0024.jpg : (453, 340, 3)\n",
      "naver_0025.jpg : (453, 340, 3)\n",
      "naver_0026.jpg : (510, 340, 3)\n",
      "naver_0027.jpg : (238, 340, 3)\n",
      "naver_0028.jpg : (420, 340, 3)\n",
      "naver_0029.jpg : (255, 340, 3)\n",
      "naver_002ass3.jpg : (832, 572, 3)\n",
      "naver_002d5.jpg : (453, 340, 3)\n",
      "naver_002ddd2.jpg : (255, 340, 3)\n",
      "naver_002ss9.jpg : (255, 340, 3)\n",
      "naver_0030.png : (600, 340, 3)\n",
      "naver_0031.jpg : (340, 340, 3)\n",
      "naver_0032.jpg : (227, 340, 3)\n",
      "naver_0033.jpg : (227, 340, 3)\n",
      "naver_0034.jpg : (340, 340, 3)\n",
      "naver_0035.jpg : (256, 340, 3)\n",
      "naver_0036.jpg : (280, 340, 3)\n",
      "naver_0037.jpg : (255, 340, 3)\n",
      "naver_0038.jpg : (227, 340, 3)\n",
      "naver_0039.jpg : (425, 340, 3)\n",
      "naver_0040.jpg : (342, 340, 3)\n",
      "naver_0041.jpg : (234, 340, 3)\n",
      "naver_0042.jpg : (513, 340, 3)\n",
      "naver_0043.jpg : (226, 340, 3)\n",
      "naver_0044.jpg : (392, 340, 3)\n",
      "naver_0045.jpg : (340, 340, 3)\n",
      "naver_0046.jpg : (340, 340, 3)\n",
      "naver_0047.jpg : (218, 340, 3)\n",
      "naver_0048.jpg : (426, 340, 3)\n",
      "naver_0049.jpg : (277, 340, 3)\n",
      "naver_0063.jpg : (223, 340, 3)\n",
      "naver_0083.jpg : (340, 340, 3)\n",
      "naver_0093.jpg : (510, 340, 3)\n",
      "naver_0099.jpg : (340, 340, 3)\n",
      "naver_00d10.jpg : (422, 340, 3)\n",
      "naver_00d29.jpg : (511, 340, 3)\n",
      "naver_00dd01.jpg : (240, 340, 3)\n",
      "naver_00dddddd02.jpg : (510, 340, 3)\n",
      "naver_00ss22.jpg : (250, 340, 3)\n",
      "naver_00sss25.jpg : (292, 340, 3)\n",
      "naver_00sss28.jpg : (227, 340, 3)\n",
      "naver_0dd002.jpg : (255, 340, 3)\n",
      "naver_0ddd023.jpg : (453, 340, 3)\n",
      "naver_0sss026.jpg : (226, 340, 3)\n",
      "navessr_0010.jpg : (227, 340, 3)\n",
      "navessr_0011.jpg : (227, 340, 3)\n",
      "navesssr_0020.jpg : (340, 340, 3)\n",
      "navser_0037.jpg : (340, 340, 3)\n",
      "navsser_0016.jpg : (220, 340, 3)\n",
      "nsssaver_0019.jpg : (340, 340, 3)\n",
      "p08b0578.jpg : (549, 976, 3)\n",
      "Permacolour-Metallic-Epoxy.jpg : (246, 401, 3)\n",
      "San-go-cong-nghiep.jpg : (750, 1000, 3)\n",
      "san-go-tu-nhien-xuoc.jpg : (359, 600, 3)\n",
      "thumb2-blue-flabby-fabric-macro-blue-flabby-background-blue-flabby-texture-flabby-backgrounds.jpg : (444, 710, 3)\n",
      "white-woven-fabric_53876-89528.jpg : (417, 626, 3)\n",
      "xx-cach-loai-bo-va-lam-kin-vet-tray-xuoc-tren-ban-.jpg : (400, 620, 3)\n"
     ]
    }
   ],
   "source": [
    "for i, bg in enumerate(os.listdir(DIR_SRC)):\n",
    "    img = cv2.imread(DIR_SRC + bg)\n",
    "    resized = cv2.resize(img, (1024, 680))\n",
    "    \n",
    "    print(f\"{bg} : {img.shape}\")\n",
    "    resized_path = DIR_DST + 'bg_' + str(i) + '.png'\n",
    "    if not os.path.exists(resized_path):\n",
    "        cv2.imwrite(resized_path, resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/'\n",
    "DIR_ORG = DATA_DIR + 'v1.0.2/'\n",
    "DIR_SYN = DATA_DIR + 'synthetic/origin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CitizenCardV1_back : 385\n",
      "CitizenCardV1_front : 400\n",
      "CitizenCardV2_back : 340\n",
      "CitizenCardV2_front : 393\n",
      "IdentificationCard_back : 384\n",
      "IdentificationCard_front : 383\n",
      "LicenseCard : 189\n",
      "Other : 36\n",
      "Passport : 10\n"
     ]
    }
   ],
   "source": [
    "for dir in os.listdir(DIR_SYN):\n",
    "    print(f\"{dir} : {len(os.listdir(DIR_SYN + dir))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cccd_v1_back',\n",
       " 'cccd_v1_front',\n",
       " 'cccd_v2_back',\n",
       " 'cccd_v2_front',\n",
       " 'cmnd_v1_back',\n",
       " 'cmnd_v1_front']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirs = os.listdir(DIR_ORG)\n",
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dirs = ['CitizenCardV1_back', 'CitizenCardV1_front', 'CitizenCardV2_back', 'CitizenCardV2_front', 'IdentificationCard_back', 'IdentificationCard_front']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cccd_v1_back : 1925 ---> CitizenCardV1_back : 385\n",
      "cccd_v1_front : 2000 ---> CitizenCardV1_front : 400\n",
      "cccd_v2_back : 1700 ---> CitizenCardV2_back : 340\n",
      "cccd_v2_front : 1965 ---> CitizenCardV2_front : 393\n",
      "cmnd_v1_back : 1920 ---> IdentificationCard_back : 384\n",
      "cmnd_v1_front : 1915 ---> IdentificationCard_front : 383\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "for j, dir in enumerate(dirs):\n",
    "    src_dir = DIR_ORG + dir + '/images/part_1/'\n",
    "    imgs = list(sorted(os.listdir(src_dir)))\n",
    "\n",
    "    dst_dir = DIR_SYN + new_dirs[j] + '/'\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "    \n",
    "    i = 0\n",
    "    while i < len(imgs):\n",
    "        img_name = imgs[i].split('.')[0]\n",
    "        img_name = '_'.join(p for p in img_name.split('_')[1:-1])\n",
    "        if img_name.startswith('_'):\n",
    "            img_name = '_'.join(p for p in img_name.split('_')[1:])\n",
    "        \n",
    "        if not os.path.exists(dst_dir + imgs[i]):\n",
    "            shutil.copy(src_dir + imgs[i], dst_dir + img_name + '.png')\n",
    "        i += 5\n",
    "\n",
    "    print(f\"{dir} : {len(imgs)} ---> {new_dirs[j]} : {len(os.listdir(dst_dir))}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create original data for `LicenceCard`, `Other`, `Passport` classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/'\n",
    "\n",
    "DIR_SRC = DATA_DIR + 'clfn/'\n",
    "DIR_DST = DATA_DIR + 'synthetic/origin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_dir = DIR_SRC + 'annos/'\n",
    "img_dir = DIR_SRC + 'images/'\n",
    "\n",
    "\n",
    "for dir in os.listdir(img_dir):\n",
    "    # Read anno file\n",
    "    anno = json.load(open(anno_dir + dir + '.json'))\n",
    "\n",
    "    if len(anno['images']) != len(anno['annotations']):\n",
    "        print(f\"Different size: {len(anno['images'])} images with {len(anno['annotations'])} annos for [{dir}]\")\n",
    "        continue\n",
    "\n",
    "    for i in range(len(anno['images'])):\n",
    "        # Take image file\n",
    "\n",
    "        img_file = anno['images'][i]['file_name']\n",
    "        img_path = img_dir + dir + '/' + img_file\n",
    "\n",
    "        if os.path.exists(img_path):\n",
    "            # Load image\n",
    "            img = cv2.imread(img_path)\n",
    "\n",
    "            # Take coordinates of segmentation points\n",
    "            coords = anno['annotations'][i]['segmentation'][0]\n",
    "            points = []\n",
    "            for i in range(len(coords)):\n",
    "                if i % 2 == 0:\n",
    "                    points.append(tuple(map(int, (coords[i], coords[i+1]))))\n",
    "\n",
    "            # Convert to numpy array\n",
    "            pts = np.array([np.array(i) for i in points])\n",
    "\n",
    "            # Get 4 corners\n",
    "            s = pts.sum(axis=1)\n",
    "            tl = pts[np.argmin(s)]\n",
    "            br = pts[np.argmax(s)]\n",
    "\n",
    "            diff = np.diff(pts, axis=1)\n",
    "            tr = pts[np.argmin(diff)]\n",
    "            bl = pts[np.argmax(diff)]\n",
    "            \n",
    "            corners = [tl, tr, br, bl]\n",
    "\n",
    "            # Define source points on original image\n",
    "            src = np.array(corners, dtype='float32')\n",
    "\n",
    "            # Get the shape of new image\n",
    "            mins = np.min(pts, axis=0)\n",
    "            x_min, y_min = map(int, (mins[0], mins[1]))\n",
    "            maxs = np.max(pts, axis=0)\n",
    "            x_max, y_max = map(int, (maxs[0], maxs[1]))\n",
    "\n",
    "            new_w = x_max - x_min\n",
    "            new_h = y_max - y_min\n",
    "\n",
    "            # Define destination points on new image\n",
    "            dst = np.array([\n",
    "                [0, 0],\n",
    "                [new_w - 1, 0],\n",
    "                [new_w - 1, new_h - 1],\n",
    "                [0, new_h]],\n",
    "                dtype='float32')\n",
    "\n",
    "            # Perform 'reversed' perspective transform\n",
    "            trans_mat = cv2.getPerspectiveTransform(src, dst)\n",
    "            warp = cv2.warpPerspective(img, trans_mat, (new_w, new_h))\n",
    "\n",
    "            dst_dir = DIR_DST + dir + '/'\n",
    "            if not os.path.exists(dst_dir):\n",
    "                os.mkdir(dst_dir)\n",
    "            cv2.imwrite(dst_dir + img_file, warp)\n",
    "\n",
    "        else:\n",
    "            print(f\"Missing image [{img_file}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `OCR` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = 'data/OCR/'\n",
    "DST_DIR = 'data/synthetic/origin/v2.0/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in os.listdir(ROOT_DIR):\n",
    "    img_dir = os.path.join(ROOT_DIR, dir, 'img/')\n",
    "    ann_dir = os.path.join(ROOT_DIR, dir, 'ann/')\n",
    "    \n",
    "    for img_file in os.listdir(img_dir):\n",
    "        img = cv2.imread(img_dir + img_file)\n",
    "        \n",
    "        ann_file = img_file + '.json'\n",
    "        if not os.path.exists(ann_dir + ann_file):\n",
    "            print(f\"No anno file for [{img_file}]\")\n",
    "            continue\n",
    "        \n",
    "        anno = json.load(open(ann_dir + ann_file))\n",
    "        # pprint(anno)\n",
    "        points = []\n",
    "        for obj in anno['objects']:\n",
    "            if obj['classTitle'] == 'square':\n",
    "                points.append(obj['points']['exterior'])\n",
    "        if len(points) == 0:\n",
    "            print(f\"Invalid anno for [{img_file}]\")\n",
    "            continue\n",
    "        \n",
    "        pts = np.array(points[0])\n",
    "\n",
    "        # Get 4 corners\n",
    "        s = pts.sum(axis=1)\n",
    "        tl = pts[np.argmin(s)]\n",
    "        br = pts[np.argmax(s)]\n",
    "\n",
    "        diff = np.diff(pts, axis=1)\n",
    "        tr = pts[np.argmin(diff)]\n",
    "        bl = pts[np.argmax(diff)]\n",
    "        \n",
    "        corners = [tl, tr, br, bl]\n",
    "\n",
    "        # Define source points on original image\n",
    "        src = np.array(corners, dtype='float32')\n",
    "\n",
    "        # Get the shape of new image\n",
    "        mins = np.min(pts, axis=0)\n",
    "        x_min, y_min = map(int, (mins[0], mins[1]))\n",
    "        maxs = np.max(pts, axis=0)\n",
    "        x_max, y_max = map(int, (maxs[0], maxs[1]))\n",
    "\n",
    "        new_w = x_max - x_min\n",
    "        new_h = y_max - y_min\n",
    "\n",
    "        # Define destination points on new image\n",
    "        dst = np.array([\n",
    "            [0, 0],\n",
    "            [new_w - 1, 0],\n",
    "            [new_w - 1, new_h - 1],\n",
    "            [0, new_h]],\n",
    "            dtype='float32')\n",
    "\n",
    "        # Perform 'reversed' perspective transform\n",
    "        trans_mat = cv2.getPerspectiveTransform(src, dst)\n",
    "        warp = cv2.warpPerspective(img, trans_mat, (new_w, new_h))\n",
    "        \n",
    "        if new_w < new_h:\n",
    "            warp = cv2.rotate(warp, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "        dst_dir = os.path.join(DST_DIR, dir)\n",
    "        if not os.path.exists(dst_dir):\n",
    "            os.mkdir(dst_dir)\n",
    "        if not os.path.exists(os.path.join(dst_dir, img_file)):\n",
    "            cv2.imwrite(os.path.join(dst_dir, img_file), warp)\n",
    "        else:\n",
    "            print(f\"Duplicate name for [{img_file}]\")\n",
    "        \n",
    "    #     break\n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `eKYC_segmentation` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = 'data/eKYC_segmentation/'\n",
    "DST_DIR = 'data/synthetic/origin/v2.0/pool/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.09s)\n",
      "creating index...\n",
      "index created!\n",
      "Invalid anno for [eKYC_dataset_1112.jpg]\n",
      "Invalid anno for [FB_IMG_1628999696646.jpg]\n",
      "Invalid anno for [eKYC_dataset_1495.jpg]\n",
      "Invalid anno for [eKYC_dataset_983.jpg]\n",
      "Invalid anno for [FB_IMG_1628997334317.jpg]\n",
      "Invalid anno for [eKYC_dataset_883.jpg]\n",
      "Invalid anno for [eKYC_dataset_1018.jpg]\n",
      "Invalid anno for [FB_IMG_1628999792318.jpg]\n",
      "Invalid anno for [FB_IMG_1629000130091.jpg]\n",
      "Invalid anno for [FB_IMG_1628998681123.jpg]\n",
      "Invalid anno for [eKYC_dataset_1734.jpg]\n",
      "Invalid anno for [FB_IMG_1628999824486.jpg]\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Invalid anno for [eKYC_dataset_255.jpg]\n",
      "Invalid anno for [eKYC_dataset_434.jpg]\n"
     ]
    }
   ],
   "source": [
    "for dir in ['train', 'val']:\n",
    "    img_dir = os.path.join(ROOT_DIR, dir, 'JPEGImages/')\n",
    "    \n",
    "    anno_file = f\"{dir}_annotations.json\"\n",
    "    coco = COCO(os.path.join(ROOT_DIR, dir, anno_file))\n",
    "    img_idx = list(coco.imgs.keys())\n",
    "    for i in img_idx:\n",
    "        img_file = coco.loadImgs(i)[0]['file_name'].split('/')[1]\n",
    "        img_name = img_file.split('.')[0]\n",
    "        if img_name.split('_')[-1] == 'flip':\n",
    "            continue\n",
    "        img_path = os.path.join(img_dir, img_file)\n",
    "        img = cv2.imread(img_path)\n",
    "        # print(img_file)\n",
    "        ann_ids = coco.getAnnIds(imgIds=i)\n",
    "        annos = coco.loadAnns(ann_ids)\n",
    "        annos = [anno for anno in annos if anno['category_id'] == 0]\n",
    "        # print(len(annos))\n",
    "        # pprint(annos[0])\n",
    "        \n",
    "        if len(annos) != 1:\n",
    "            print(f\"Invalid anno for [{img_file}]\")\n",
    "            continue\n",
    "        \n",
    "        segm = annos[0]['segmentation'][0]\n",
    "        points = []\n",
    "        for i in range(len(segm)-1):\n",
    "            if i % 2 == 0:\n",
    "                points.append(list(map(int, (segm[i], segm[i+1]))))\n",
    "        pts = np.array(points)\n",
    "        \n",
    "        # Get 4 corners\n",
    "        s = pts.sum(axis=1)\n",
    "        tl = pts[np.argmin(s)]\n",
    "        br = pts[np.argmax(s)]\n",
    "\n",
    "        diff = np.diff(pts, axis=1)\n",
    "        tr = pts[np.argmin(diff)]\n",
    "        bl = pts[np.argmax(diff)]\n",
    "        \n",
    "        corners = [tl, tr, br, bl]\n",
    "\n",
    "        # Define source points on original image\n",
    "        src = np.array(corners, dtype='float32')\n",
    "\n",
    "        # Get the shape of new image\n",
    "        mins = np.min(pts, axis=0)\n",
    "        x_min, y_min = map(int, (mins[0], mins[1]))\n",
    "        maxs = np.max(pts, axis=0)\n",
    "        x_max, y_max = map(int, (maxs[0], maxs[1]))\n",
    "\n",
    "        new_w = x_max - x_min\n",
    "        new_h = y_max - y_min\n",
    "\n",
    "        # Define destination points on new image\n",
    "        dst = np.array([\n",
    "            [0, 0],\n",
    "            [new_w - 1, 0],\n",
    "            [new_w - 1, new_h - 1],\n",
    "            [0, new_h]],\n",
    "            dtype='float32')\n",
    "\n",
    "        # Perform 'reversed' perspective transform\n",
    "        trans_mat = cv2.getPerspectiveTransform(src, dst)\n",
    "        warp = cv2.warpPerspective(img, trans_mat, (new_w, new_h))\n",
    "        \n",
    "        if new_w < new_h:\n",
    "            warp = cv2.rotate(warp, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        \n",
    "        if not os.path.exists(os.path.join(DST_DIR, img_file)):\n",
    "            cv2.imwrite(os.path.join(DST_DIR, img_file), warp)\n",
    "        else:\n",
    "            print(f\"Duplicate name for [{img_file}]\")\n",
    "    \n",
    "    #     break    \n",
    "    # break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/synthetic/'\n",
    "DIR_BG = DATA_DIR + 'resized_bg/'\n",
    "DIR_ORG = DATA_DIR + 'origin/v2.0/'\n",
    "DIR_SYN = DATA_DIR + 'synthesis/'\n",
    "\n",
    "# for s in ['images/', 'masks']:\n",
    "#     if not os.path.exists(DIR_SYN + s):\n",
    "#         os.mkdir(DIR_SYN + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CitizenCardV1_back : 49\n",
      "CitizenCardV1_front : 719\n",
      "CitizenCardV2_back : 44\n",
      "CitizenCardV2_front : 33\n",
      "IdentificationCard_back : 68\n",
      "IdentificationCard_front : 840\n",
      "LicenseCard : 170\n",
      "Other : 36\n",
      "Passport : 10\n"
     ]
    }
   ],
   "source": [
    "dirs = list(sorted(os.listdir(DIR_ORG)))\n",
    "for dir in dirs:\n",
    "    print(f\"{dir} : {len(os.listdir(DIR_ORG + dir))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(width: int, height: int, distortion_scale: float):\n",
    "    \"\"\"Get parameters for ``perspective`` for a random perspective transform.\n",
    "\n",
    "    Args:\n",
    "        width (int): width of the image.\n",
    "        height (int): height of the image.\n",
    "        distortion_scale (float): argument to control the degree of distortion and ranges from 0 to 1.\n",
    "\n",
    "    Returns:\n",
    "        List containing [top-left, top-right, bottom-right, bottom-left] of the original image,\n",
    "        List containing [top-left, top-right, bottom-right, bottom-left] of the transformed image.\n",
    "    \"\"\"\n",
    "    half_height = height // 2\n",
    "    half_width = width // 2\n",
    "    topleft = np.array([\n",
    "        int(np.random.randint(0, int(distortion_scale * half_width) + 1, size=(1,))),\n",
    "        int(np.random.randint(0, int(distortion_scale * half_height) + 1, size=(1,))),\n",
    "    ])\n",
    "    topright = np.array([\n",
    "        int(np.random.randint(width - int(distortion_scale * half_width) - 1, width, size=(1,))),\n",
    "        int(np.random.randint(0, int(distortion_scale * half_height) + 1, size=(1,))),\n",
    "    ])\n",
    "    botright = np.array([\n",
    "        int(np.random.randint(width - int(distortion_scale * half_width) - 1, width, size=(1,))),\n",
    "        int(np.random.randint(height - int(distortion_scale * half_height) - 1, height, size=(1,))),\n",
    "    ])\n",
    "    botleft = np.array([\n",
    "        int(np.random.randint(0, int(distortion_scale * half_width) + 1, size=(1,))),\n",
    "        int(np.random.randint(height - int(distortion_scale * half_height) - 1, height, size=(1,))),\n",
    "    ])\n",
    "    startpoints = np.array([[0, 0], [width - 1, 0], [width - 1, height - 1], [0, height - 1]], dtype='float32')\n",
    "    endpoints = np.array([topleft, topright, botright, botleft], dtype='float32')\n",
    "    return startpoints, endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714.4121450568117\n",
      "461.1123405514831\n"
     ]
    }
   ],
   "source": [
    "global_avg_w, global_avg_h = 0, 0\n",
    "\n",
    "for j, dir in enumerate(dirs):\n",
    "    avg_w, avg_h = 0, 0\n",
    "    for i, file in enumerate(os.listdir(DIR_ORG + dir + '/')):\n",
    "        img = cv2.imread(DIR_ORG + dir + '/' + file)\n",
    "\n",
    "        h, w = img.shape[:2]\n",
    "\n",
    "        avg_w += w\n",
    "        avg_h += h\n",
    "\n",
    "    global_avg_w += avg_w / len(os.listdir(DIR_ORG + dir + '/'))\n",
    "    global_avg_h += avg_h / len(os.listdir(DIR_ORG + dir + '/'))\n",
    "\n",
    "print(global_avg_w / len(dirs))\n",
    "print(global_avg_h / len(dirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_obj(img):\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    new_h = int(h * 720 / w)\n",
    "    if new_h > 480:\n",
    "        new_w = int(720 * 480 / new_h)\n",
    "        img = cv2.resize(img, (new_w, 480))\n",
    "    else:\n",
    "        img = cv2.resize(img, (720, new_h))\n",
    "    \n",
    "    ratio = np.random.choice(np.arange(1.35, 1.4, 0.05))\n",
    "    h, w = img.shape[:2]\n",
    "    img = cv2.resize(img, (int(ratio * w), int(ratio * h)))\n",
    "    # print(w, h)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(img, width, height):\n",
    "    # Perspective transform\n",
    "    src, dst = get_params(width, height, distortion_scale=0.2)\n",
    "    trans_mat = cv2.getPerspectiveTransform(src, dst)\n",
    "    warp = cv2.warpPerspective(img, trans_mat, (width, height))\n",
    "\n",
    "    mins = np.min(dst, axis=0)\n",
    "    x_min, y_min = map(int, (mins[0], mins[1]))\n",
    "    maxs = np.max(dst, axis=0)\n",
    "    x_max, y_max = map(int, (maxs[0], maxs[1]))\n",
    "\n",
    "    cut = warp[y_min:y_max, x_min:x_max]\n",
    "    \n",
    "    diff = np.array([[x_min, y_min]])\n",
    "    dst_cut = dst - diff\n",
    "\n",
    "    return cut, dst_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_rotate(bg, img, dst, p):\n",
    "    height, width = img.shape[:2]\n",
    "    # Random rotate\n",
    "    if p == 1:\n",
    "        rt_bg = cv2.rotate(bg, cv2.ROTATE_180)\n",
    "        rt_cut = cv2.rotate(img, cv2.ROTATE_180)\n",
    "        tl = np.array([width - dst[2][0], height - dst[2][1]])\n",
    "        tr = np.array([width - dst[3][0], height - dst[3][1]])\n",
    "        br = np.array([width - dst[0][0], height - dst[0][1]])\n",
    "        bl = np.array([width - dst[1][0], height - dst[1][1]])\n",
    "        new_dst = np.array([tl ,tr, br, bl])\n",
    "        return rt_bg, rt_cut, new_dst\n",
    "    elif p == 2:\n",
    "        rt_bg = cv2.rotate(bg, cv2.ROTATE_90_CLOCKWISE)\n",
    "        rt_cut = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "        tl = np.array([height - dst[3][1], dst[3][0]])\n",
    "        tr = np.array([height - dst[0][1], dst[0][0]])\n",
    "        br = np.array([height - dst[1][1], dst[1][0]])\n",
    "        bl = np.array([height - dst[2][1], dst[2][0]])\n",
    "        new_dst = np.array([tl ,tr, br, bl])\n",
    "        return rt_bg, rt_cut, new_dst\n",
    "    elif p == 3:\n",
    "        rt_bg = cv2.rotate(bg, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        rt_cut = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        tl = np.array([dst[1][1], width - dst[1][0]])\n",
    "        tr = np.array([dst[2][1], width - dst[2][0]])\n",
    "        br = np.array([dst[3][1], width - dst[3][0]])\n",
    "        bl = np.array([dst[0][1], width - dst[0][0]])\n",
    "        new_dst = np.array([tl ,tr, br, bl])\n",
    "        return rt_bg, rt_cut, new_dst\n",
    "    else:\n",
    "        return bg, img, dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coloured_mask(mask):\n",
    "    r = np.zeros_like(mask).astype(np.uint8)\n",
    "    g = np.zeros_like(mask).astype(np.uint8)\n",
    "    b = np.zeros_like(mask).astype(np.uint8)\n",
    "    r[mask == 1], g[mask == 1], b[mask == 1] = [128, 0, 128]\n",
    "    coloured_mask = np.stack([r, g, b], axis=2)\n",
    "    return coloured_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(img_info, rate=1, show_annos=False):\n",
    "    # Init lists for annotation\n",
    "    images, annotations = [], []\n",
    "\n",
    "    org_img = cv2.imread(img_info['path'])\n",
    "    img = org_img.copy()\n",
    "\n",
    "    for r in range(rate):\n",
    "        ## Resize img with random ratio\n",
    "        img = resize_obj(img)\n",
    "        height, width = img.shape[:2]\n",
    "        \n",
    "        ## Transform img\n",
    "        cut, dst_cut = transform(img, width, height)\n",
    "        print(cut.shape)\n",
    "        cut_height, cut_width = cut.shape[:2]\n",
    "        \n",
    "        ## Get random background\n",
    "        bg_num = np.random.randint(0, 130)\n",
    "        bg = cv2.imread(DIR_BG + f'bg_{bg_num}.png')\n",
    "        \n",
    "        ## Random rotate\n",
    "        p = np.random.choice(4, p=[0.25, 0.25, 0.25, 0.25])\n",
    "        bg, cut, dst_cut = random_rotate(bg, cut, dst_cut, p)\n",
    "        bg_org = bg.copy()\n",
    "        bg_height, bg_width = bg.shape[:2]\n",
    "        if p == 2 or p == 3:\n",
    "            cut_width, cut_height = cut_height, cut_width\n",
    "        print(p, cut.shape)\n",
    "        \n",
    "        ## Create mask of object\n",
    "        mask_cut = np.zeros(cut.shape, dtype='uint8')        \n",
    "        cv2.drawContours(mask_cut, [dst_cut.reshape((-1, 1, 2)).astype('int32')], -1, (255, 255, 255), -1)\n",
    "\n",
    "        ## Create random root point\n",
    "        print(bg.shape, img.shape, cut.shape)\n",
    "        rand_x = np.random.randint(0, bg_width - cut_width - 1)\n",
    "        rand_y = np.random.randint(0, bg_height - cut_height - 1)\n",
    "        root_point = (rand_x, rand_y)\n",
    "\n",
    "        ## Calculate new corners and convert to segmentation for annos\n",
    "        corners = dst_cut + np.array([[rand_x, rand_y]])\n",
    "\n",
    "        ## Combine object with random background to create composite image\n",
    "        fin_cut = cv2.cvtColor(cut, cv2.COLOR_RGB2RGBA)\n",
    "        blue, green, red, a = cv2.split(fin_cut)\n",
    "        a = mask_cut\n",
    "        fin_cut[:, :, 0] = cut[:, :, 0]\n",
    "        fin_cut[:, :, 1] = cut[:, :, 1]\n",
    "        fin_cut[:, :, 2] = cut[:, :, 2]\n",
    "        fin_cut[:, :, 3] = a[:, :, 0]\n",
    "\n",
    "        alpha_s = fin_cut[:, :, 3] / 255.\n",
    "        alpha_l = 1. - alpha_s\n",
    "\n",
    "        for c in range(3):\n",
    "            bg[rand_y:rand_y+cut_height, rand_x:rand_x+cut_width, c] = (alpha_s * cut[:, :, c] +\n",
    "                                alpha_l * bg[rand_y:rand_y+cut_height, rand_x:rand_x+cut_width, c])\n",
    "\n",
    "        ## Smooth edges with Gaussian Blur\n",
    "        mask_bg = np.zeros(bg.shape, dtype=np.uint8)\n",
    "        mask_bg[rand_y:rand_y+cut_height, rand_x:rand_x+cut_width] = mask_cut\n",
    "\n",
    "        alpha = cv2.GaussianBlur(mask_bg, (15, 15), 50).astype('float32') / 255.\n",
    "\n",
    "        comp = alpha * bg.astype('float32') + (1 - alpha) * bg_org.astype('float32')\n",
    "\n",
    "        \n",
    "        ## Show annos\n",
    "        if show_annos:\n",
    "            # Bounding box\n",
    "            cv2.rectangle(comp, (rand_x, rand_y), (rand_x+cut_width, rand_y+cut_height), (0, 255, 0))\n",
    "\n",
    "            # Corners and segmentation mask\n",
    "            for corner in corners:\n",
    "                cv2.circle(comp, tuple(map(int, corner)), radius=5, color=(0, 0, 255), thickness=-1)\n",
    "            mask = np.zeros((bg_height, bg_width), dtype=np.uint8)\n",
    "            mask = cv2.fillPoly(mask, np.int32([corners]), 1)\n",
    "            rgb_mask = get_coloured_mask(mask)\n",
    "            # print(comp.shape, rgb_mask.shape)\n",
    "            comp = cv2.addWeighted(comp.astype(np.uint8), 1, rgb_mask, 0.35, 0)\n",
    "\n",
    "            # Root point\n",
    "            cv2.circle(comp, root_point, radius=5, color=(255, 0, 0), thickness=-1)\n",
    "        \n",
    "\n",
    "        # comp, corners = random_rotate(comp, corners, p)\n",
    "        segment = [[]]\n",
    "        for corner in corners:\n",
    "            segment[0].extend(list(corner))\n",
    "                \n",
    "        ## Write composite image & mask image\n",
    "        if not os.path.exists(img_info['dst_dir'] + 'images/'):\n",
    "            os.mkdir(img_info['dst_dir'] + 'images/')\n",
    "        img_name = f\"{img_info['class']}_{img_info['num']}_aug_{r}.png\"\n",
    "        cv2.imwrite(img_info['dst_dir'] + 'images/' + img_name, comp)\n",
    "\n",
    "        # mask_name = f\"{img_info['class']}_{img_info['num']}_aug_{r}_mask.png\"\n",
    "        # cv2.imwrite(DIR_SYN + 'masks/' + mask_name, mask_bg)\n",
    "\n",
    "        ## Write annos\n",
    "        image = {\n",
    "            'id': img_info['start_id'] + r,\n",
    "            'file_name': img_name,\n",
    "            'height': comp.shape[0],\n",
    "            'width': comp.shape[1]\n",
    "            # 'mask_name': mask_name\n",
    "        }\n",
    "\n",
    "        annotation = {\n",
    "            'id': img_info['start_id'] + r,\n",
    "            'image_id': img_info['start_id'] + r,\n",
    "            'iscrowd': 0,\n",
    "            'category_id': img_info['cls_id'],\n",
    "            'bbox': [rand_x * 1., rand_y * 1., cut_width * 1., cut_height * 1.],\n",
    "            'area': cut_width * cut_height * 1.,\n",
    "            'segmentation': segment\n",
    "        }\n",
    "\n",
    "        images.append(image)\n",
    "        annotations.append(annotation)\n",
    "    return images, annotations\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, annotations = [], []\n",
    "curr_id = 0\n",
    "DATA_VER = 'v2.1'\n",
    "\n",
    "for cls_id, dir in enumerate(dirs):\n",
    "    src_dir = DIR_ORG + dir + '/'\n",
    "    dst_dir = DIR_SYN + DATA_VER + '/'\n",
    "    \n",
    "    num_img = len(os.listdir(src_dir))\n",
    "    # print(num_img)\n",
    "    if num_img > 400:\n",
    "        rate = 1\n",
    "    else:\n",
    "        rate = 400 // num_img\n",
    "\n",
    "    for img_num, img_file in enumerate(os.listdir(src_dir)):\n",
    "        img_path = src_dir + img_file\n",
    "        \n",
    "        img_info = {\n",
    "            'start_id': curr_id,\n",
    "            'num': img_num,\n",
    "            'path': img_path,\n",
    "            'class': dir,\n",
    "            'cls_id': cls_id + 1,\n",
    "            'dst_dir': dst_dir\n",
    "        }\n",
    "        \n",
    "        images_, annotations_ = augment(img_info, rate=rate, show_annos=False)\n",
    "        images.extend(images_)\n",
    "        annotations.extend(annotations_)\n",
    "\n",
    "        curr_id += rate\n",
    "        # break\n",
    "    \n",
    "    print(f\"{dir} : {num_img * rate}\")\n",
    "\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DIR_SYN + DATA_VER + '/annotations.json', 'w+') as f:\n",
    "    json.dump({\n",
    "        'info': {\n",
    "            'description': \"eKYC Synthetic Segmentation Dataset\",\n",
    "            'version': DATA_VER,\n",
    "            'date_created': \"20/04/2022\",\n",
    "            'contributor': \"phatdp, cuonghv, linhlth\"\n",
    "        },\n",
    "        'categories': [\n",
    "            {'id': 1, 'name': \"CitizenCardV1_back\"},\n",
    "            {'id': 2, 'name': \"CitizenCardV1_front\"},\n",
    "            {'id': 3, 'name': \"CitizenCardV2_back\"},\n",
    "            {'id': 4, 'name': \"CitizenCardV2_front\"},\n",
    "            {'id': 5, 'name': \"IdentificationCard_back\"},\n",
    "            {'id': 6, 'name': \"IdentificationCard_front\"},\n",
    "            {'id': 7, 'name': \"LicenseCard\"},\n",
    "            {'id': 8, 'name': \"Other\"},\n",
    "            {'id': 9, 'name': \"Passport\"}\n",
    "        ],\n",
    "        'images': images,\n",
    "        'annotations': annotations\n",
    "    }, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7641052d6760fd4b0577988d5c63a2ad36bf4fbb0e0da31283f90db6ffd2260e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ve1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
